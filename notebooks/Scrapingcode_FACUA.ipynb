{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones:\n",
    "# Beautifulsoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Requests\n",
    "import requests\n",
    "\n",
    "# Otras\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "from time import sleep\n",
    "import random\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "import os\n",
    "src_path = os.path.abspath(os.path.join(os.pardir, 'src'))\n",
    "sys.path.append(src_path)\n",
    "# from support import obtener_sopa\n",
    "# from support import sacar_tabla\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creacion de Urls básicas de extraccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_facua = \"https://super.facua.org/\"\n",
    "\n",
    "# Urls supermercados\n",
    "supermercados=['mercadona','carrefour','eroski','dia','hipercor','alcampo']\n",
    "urls_supermercados = [f\"{url_facua}{keyword}/\" for keyword in supermercados]\n",
    "\n",
    "# Urls aceite girasol\n",
    "producto='aceite-de-girasol'\n",
    "urlsgirasol = [f\"{url}{producto}/\" for url in urls_supermercados]\n",
    "\n",
    "# Urls aceite aceite de oliva\n",
    "producto='aceite-de-oliva'\n",
    "urlsoliva = [f\"{url}{producto}/\" for url in urls_supermercados]\n",
    "tiposubproductoaceiteoliva=['suave-e-intenso','virgen','virgen-extra']\n",
    "urlsolivasubtipos=[]\n",
    "for producto2 in tiposubproductoaceiteoliva:\n",
    "    urlsolivasubtipos.extend([f\"{url}{producto2}/\" for url in urlsoliva])\n",
    "\n",
    "# Urls aceite aceite de oliva\n",
    "producto='leche'\n",
    "urlsleche = [f\"{url}{producto}/\" for url in urls_supermercados]\n",
    "tiposubproductoleche=['enriquecida','entera-semi-desnatada','sin-lactosa']\n",
    "urlslecheubtipos=[]\n",
    "for producto2 in tiposubproductoleche:\n",
    "    urlslecheubtipos.extend([f\"{url}{producto2}/\" for url in urlsleche])\n",
    "\n",
    "# Juntar todas las urls en una lista\n",
    "Listaurls=urlsgirasol+urlsolivasubtipos+urlslecheubtipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listaurls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Busqueda asincrona de Urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función asíncrona para obtener el contenido de una URL y procesarlo con BeautifulSoup\n",
    "async def search(url, session):\n",
    "    async with session.get(url) as response:\n",
    "        html = await response.text()\n",
    "        return BeautifulSoup(html, \"html.parser\")  # Retorna la sopa de cada URL\n",
    "\n",
    "# Función principal para manejar las peticiones asíncronas\n",
    "async def main(urls):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [search(url, session) for url in urls]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        return results\n",
    "    # Ejecución de corutinas en entornos interactivos\n",
    "\n",
    "listasopas = await main(Listaurls)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encuentra todos los enlaces que coincidan con el patrón\n",
    "listatotalurlsproductos=[]\n",
    "\n",
    "for sopa in listasopas:\n",
    "    # Encuentra todas las etiquetas <a> con la clase 'btn-unirme'\n",
    "    enlaces = sopa.find_all('a', class_=lambda c: c and 'btn-unirme' in c)\n",
    "    \n",
    "    # Extrae el atributo 'href' de cada enlace encontrado y agrégalo a la lista si existe\n",
    "    for enlace in enlaces:\n",
    "        href = enlace.get('href')\n",
    "        if href and href.startswith('https://'):\n",
    "            if href.endswith('unirme/'):\n",
    "                None\n",
    "            else:\n",
    "                listatotalurlsproductos.append(href)\n",
    "# listatotalurlsproductos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "listasopasproductos=[]\n",
    "for url in listatotalurlsproductos:\n",
    "    response = requests.get(url)\n",
    "    # Comprobar que la solicitud fue exitosa\n",
    "    if response.status_code == 200:\n",
    "        # Convertir el contenido de la página a BeautifulSoup\n",
    "        sopa = BeautifulSoup(response.text, 'html.parser')\n",
    "        listasopasproductos.append(sopa)\n",
    "    else:\n",
    "        print(f\"Error al acceder a {url}: Código de estado {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1543\n",
      "1543\n"
     ]
    }
   ],
   "source": [
    "# Comprobar si todo esta sacado\n",
    "print(len(listatotalurlsproductos))\n",
    "print(len(listasopasproductos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unasopa=listasopasproductos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sopasdectuosas=[]\n",
    "sopasbuenas=[]\n",
    "for i in listasopasproductos:\n",
    "    try:\n",
    "        # Extraer el título del <h2>\n",
    "        title = i.find('h2').text.strip('Tabla de precios por día para')\n",
    "\n",
    "        info = [item.text.strip() for item in i.select('li.breadcrumb-item')][1:]\n",
    "\n",
    "        # Extraer datos de la tabla\n",
    "        data = []\n",
    "        for fila in i.find_all('tr')[1:]:  # Omitir la fila de encabezados\n",
    "            columnas = fila.find_all('td')\n",
    "            dia = columnas[0].text.strip()\n",
    "            precio = columnas[1].text.strip()\n",
    "            variacion = columnas[2].text.strip()\n",
    "            data.append([dia, precio, variacion])\n",
    "\n",
    "        # Convertir en DataFrame de pandas\n",
    "        df = pd.DataFrame(data, columns=[\"Día\", \"Precio (€)\", \"Variación\"])\n",
    "\n",
    "        # Agregar el título como una columna adicional\n",
    "        df['Nombre'] = title\n",
    "        df['Supermercado'] = info[0]\n",
    "        df['Tipo producto'] = info[1]\n",
    "        try:\n",
    "            df['Tipo subproducto'] = info[2]\n",
    "        except: None\n",
    "        sopasbuenas.append(df)\n",
    "    except:\n",
    "        sopasdectuosas.append(i)\n",
    "\n",
    "df_unido=pd.concat(sopasbuenas,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1543\n",
      "1269\n",
      "274\n"
     ]
    }
   ],
   "source": [
    "print(len(listasopasproductos))\n",
    "print(len(sopasbuenas))\n",
    "print(len(sopasdectuosas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sopasbuenas2 = []\n",
    "sopasdectuosas2 = []\n",
    "titulosdefect=[]\n",
    "\n",
    "for i in sopasdectuosas:\n",
    "    try:\n",
    "        # Extraer el título del <h2>\n",
    "        title = i.find('h2').text.strip('Comparativa de precios de')\n",
    "        titulosdefect.append(title)\n",
    "        info = [item.text.strip() for item in i.select('li.breadcrumb-item')][1:]\n",
    "\n",
    "        # # Extraer datos de la tabla\n",
    "        tabla_precios = sopa.find_next(\"table\")\n",
    "\n",
    "        # Si la tabla está en divs en lugar de una tabla HTML\n",
    "        if not tabla_precios:\n",
    "            tabla_precios = sopa.find_next(\"div\", class_=\"tabla-precios\")  # Ajusta la clase si es necesario\n",
    "\n",
    "        # Almacena los datos en listas y convierte a DataFrame\n",
    "        if tabla_precios:\n",
    "            filas = tabla_precios.find_all(\"tr\")\n",
    "            data = []\n",
    "            for fila in filas:\n",
    "                columnas = fila.find_all([\"td\", \"th\"])  # Considera tanto headers como datos\n",
    "                datos = [columna.get_text(strip=True) for columna in columnas]\n",
    "                if len(datos) == 3:  # Solo agrega filas que tengan las tres columnas Día, Precio, Variación\n",
    "                    data.append(datos)\n",
    "\n",
    "            # Crear el DataFrame con encabezados específicos\n",
    "        df = pd.DataFrame(data, columns=[\"Día\", \"Precio (€)\", \"Variación\"]).drop([0, 1]).reset_index(drop=True)\n",
    "        # Agregar el título como una columna adicional\n",
    "        df['Nombre'] = title\n",
    "        df['Supermercado'] = info[0]\n",
    "        df['Tipo producto'] = info[1]\n",
    "        try:\n",
    "            df['Tipo subproducto'] = info[2]\n",
    "        except: None\n",
    "        sopasbuenas2.append(df)\n",
    "    \n",
    "    except:\n",
    "        sopasdectuosas2.append(i)\n",
    "\n",
    "df_unido2=pd.concat(sopasbuenas2,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unido_final=pd.concat([df_unido,df_unido2],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Día</th>\n",
       "      <th>Precio (€)</th>\n",
       "      <th>Variación</th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Supermercado</th>\n",
       "      <th>Tipo producto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62449</th>\n",
       "      <td>27/08/2024</td>\n",
       "      <td>1,69</td>\n",
       "      <td>=</td>\n",
       "      <td>Leche entera ASTURIANA, botella 1,5 lit</td>\n",
       "      <td>Eroski</td>\n",
       "      <td>Leche</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Día Precio (€) Variación  \\\n",
       "62449  27/08/2024       1,69         =   \n",
       "\n",
       "                                        Nombre Supermercado Tipo producto  \n",
       "62449  Leche entera ASTURIANA, botella 1,5 lit       Eroski         Leche  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unido_final.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unido_final['Día'] = pd.to_datetime(df_unido_final['Día'], dayfirst=True)\n",
    "df_unido_final['Precio (€)'] = df_unido_final['Precio (€)'].str.replace(',', '.').astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132187, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unido_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Día              datetime64[ns]\n",
       "Precio (€)              float64\n",
       "Variación                object\n",
       "Nombre                   object\n",
       "Supermercado             object\n",
       "Tipo producto            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unido_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_actual = datetime.now().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unido.to_csv(f'../data/base/DatospreciosFACUA_{fecha_actual}.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
